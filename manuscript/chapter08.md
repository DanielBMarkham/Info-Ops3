# Learning Foundation Complete

One of the more interesting aspects of negatives stacking and the importance of being wrong is how if affects all sorts of political interactions. As it turns out, quite surprisingly, people complaining, even in extremely vague language, are the bedrock of all progress of western civilzation.

It's quite easy to take an instance of somebody complaining in vague terms, perhaps somebody saying "this sux!", and point out how completely useless that kind of comment is. And that's correct! All negative comments turn out to be useless. It is the comment itself that begins the process of analysis that then leads to something productive. Once we narrow down things to the point where it doesn't matter whether we act, then and only then do we add a test.

That test is made using the same language of negatives that we have stacked to find a particular area of interest that we're currently exploring. 

This does not guarantee success. Or that we're right. But it guarantees that we will have the same experience most all of the time. Science, as it turns out, relies on negatives stacking, tests corresponding to that uniquely-experienced area of inquiry (using the same language as the area it's described in), and reproducible results. That's it.

We'd like to think of science as being the progress of humans stacked on top of one another over the ages. One writer described it as "standing on the shoulders of giants". And that's true. But it's not true in a literal way. We are not literally standing on the shoulders of giants, nor are we using the things we've written down over the years to do that, as much as we'd like to think otherwise. We are not taking the words of previous people and adding our own words to them to make something new. 

That's probably the most surprising thing of all, out of all of this. 

What we're doing is creating areas where a small group of people have an interest in exploring, or silos, where we have agreed-upon negatives that stack to create testable, reproducible, experiments that correspond to the area we're trying to explore or the thing we're trying to find. Since those negativts are by definitions unprecise and vague, that language does not have to resolve itself into some sort of formal, logical, self-consistent graph of meaning. So while we can certainly use vague language to describe whatever our target is, and we can use vague language to describe how we reproduce things, the corresponding part of this, the silo'ed negatives stacking part? That is a socially-constructed boundary of vagaries. And that's fine. It seems to work quite well for everybody concerned.

There was a time when the human language was small enough and the concepts generally understood in a shared way well enough, that you could read a book and then go do the thing while understanding the entire "stack" of tech you're using to accomplish that. Those days are long gone, but we still have the illusion that they're not, mainly because of the limits of human cognition. 

This is why it's possible to describe lots of experiments that seem like they might work to experts in the field when in fact they're not reproducible or the experiments are reproducible but the results aren't. It's not a problem with the experts or the field of study.

Popper got very close to this when he said that all science should be falsifiable. It's not that it should be falsifiable as much as it should contain self-consistent vague language that describes a reproducible, falsifiable system of inquiry. 

Dang, that's a mouthful of words, isn't it?

So the beginning of the learning loop, by definition, is a vague, formless, negative feeling. This feeling is based either on sensory input, some internal caluculation, or a sequence of either of the two in combination. But make no mistake, it is that beginning, it is that that vague sense of negativeness, where learning begins.

We cannot natively, naively, or intuitively see this. The human brain is a cheater. Describing how learning happens, like we just did, is a mess of words and complexities. When we're diving down into this particular pool, it's quite easy to think either the entire concept is very fuzzy and we'll never, ever reach our goals of understanding learning at scale. Brain don't care about any of this. 

Biological systems work on this same learning principle. But they don't care about the rigor of reproducibility, vagueness, falsifibility, or negatives stacking to create boundaries as much as science does. (Even if they do in practice). That's because biological systems only have to believe that they understand what's going on and that there's a cause and effect in place. Scientific systems have to **know** and be able to describe all of that. 

The word "know" here is also quite interesting. Once we dive down microscopically to the quantum level? Cause and effect? Locality? Particles? Uniqueness? Even the idea of space and time? They become amorphous. 

Indeed, there are a lot of philosophers of science that are either frequentists or bayesians. By that I mean that they do not view science as a lock-step, cause-and-effect area of exploration as much as a "set this up, do this thing, and mostly this other thing will happen" situation. Sometimes, like dropping a hammer on Earth, the word "mostly" corresponds to 100%. Sometimes, like at the quantum level, the word "mostly" corresponds to a probably field, matrices of values with probabilities corresponding in multiple dimensions. 

But you know? No matter what physical reality is, brain don't care. If it did care? If we had to evolve as a biological species the same way as a computer program has to be coded? We never would have evolved at all. It's important to understand that while the fundamentals of learning for both biological, machine, and social systems, the actual way that learning takes place varies drastically between all three. 

What we'll end up doing, now that we've established our foundation, is taking these fundamentals and comparing the with the observed situation in all three systems to see where we can create, improve, and measure learning at scale.

## The Structure of Learning

## Making up the Bricks
We have bricks, we know what the building looks like

## The Canyon

Ditch-digging, the universe, and crossing the chasm of human experience; balancing invention and practicality

![](resources/images/the-canyon-intro.png)

Over the weekend I was studying the life of Martin Heidegger. Here's the super-short, mostly-wrong version: Heidegger understood language's inability to describe and ultimately deal with reality, so he used the German language's wonderful mix-and-match-word-parts to try to fix it. Using some words to fix the problem with all words is like trying to put out a fire with kerosene; the more you try, the bigger the problem gets.

He ended publishing over 47 volumes. Most of his work is not published. He spent a lot of time thinking about the meaning and differences of things like being-to-meaning, being-about-meaning, being-of-meaning, being-around-meaning, and so forth (I made up these terms, but they are indicative of the types of things he spent his life on. This guy didn't do a lot of ditch-digging.)

![Wow! Great books! Think I'll wait for the Netflix 143-episode series. I like to think of Heidegger as sort of a fundamentalist pre-socratic.](resources/images/Martin-Heidegger.jpg)


You can't start believing your own bullshit. Put more kindly, you have to be arrogant and smart to come up with a unique and useful idea or two. (That doesn't mean you have to be unpleasant.) However by being arrogant and smart, you're prone to taking those ideas and turning them into a lifetime of deeper and deeper digging into how arrogant and smart you are. Every philosopher that have good biographies took some great ideas and went a thousand times farther than they probably should have. It's not the fault of those people; we tend to find lost keys somewhere around the lamppost. That's not because lost keys go there, it's because that's the place we can see best. People who have these great ideas see a little part, they create their own lamppost, so of course they're going to keep looking around that lamppost to see whatever other cool things they can dig up.

Still, you should never be afraid of being a bit arrogant, coming up with new stuff, or joining together old stuff into something that's either new or looks pretty cool. The world needs folks like that. Whether that's your lamppost or not, it's a cool set of keys you found that somebody might want. Just keep it all in context.

With that in mind, I needed to update my understanding of how people understand the world. The canyon diagram shows that there are two basic ways of existing in and thinking about the universe you're in, abstract logical/mathematical reasoning, and flexible, totally-ambiguous spoken/performed language. Of course, all of us constantly use both of these, move around them fluidly, and join them together in various ways, but most times we are unaware. We forget this stuff, then we end up spending our life writing 47 volumes of impenetrable stuff that might be useful or might be total bullshit, nobody really knows. They'll argue about it forever.

![Heidegger tried to use more and more language, some of his own design, to make the right side of the canyon go away. Everything was ultimately political and social. Language itself existed as sort of an ultimate truth, over the centuries passing down from generation-to-generation as it tried to express itself](resource/images/../../resources/images/canyon-and-modes-of-existence.png)


It's not just academic philosopher types. This happens to folks writing computer programs and cloud systems as well. You come up with something pretty cool, something that gets lots of attention, then you spend far too much time riding that mechanical pony around long after your dime ran out outside the local Walmart. Other kids want to ride too.

To avoid this tendency while still trying to be a worthwhile member of society, I've always sketched out any sort of abstract concept or problem I'm working on enough to find a way forward to a larger goal, then either discarded or actively tried to forget it, instead focusing entirely on the goal. From time-to-time I come back to these sketches to see if I can bang them together into something else that's cool, but once again only enough to find a way forward to a larger goal. You start focusing on your own abstractions too much, you'll end up talking to your oatmeal. You don't want to talk to your oatmeal.

![Sketch, align, reason, use, discard, rinse and repeat](resources/images/it-aint-much-but-its-honest-work.gif)

The canyon diagram helps me reason about the kinds of things people do, the modes of thought they have, and how different modes really follow different rules. If you don't understand those rules, you can't effectively engage with what's going on. It points out obvious things (to me), like the natural opposite of politics is science, or that total faith and total truth, while giving a happy feeling of certainty, are diametrically different things.

I believe I can use this sketch to take most large movements in mankind, things like rationalism, existentialism, fideism, etc., and map them. I can even show how these movements have changed over time by tracking how their location on the diagram changes. More importantly, all conversations about building cool new stuff or fixing broken stuff live here. It's the map. That's what I needed.

But however it turns out, for now I've got my modes of existence mapped into categories I can attempt to use to talk more about productive conversations. If it works past that point, that's cool. If not, I'll sketch out another one.

Stay ego-free, my friends.

---



Next up, how biological systems learn and how they can be super-intelligent without actually knowing anything.
